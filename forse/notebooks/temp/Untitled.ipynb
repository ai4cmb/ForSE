{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/global/homes/k/krach/usr/python_prefix_3.7/lib/python3.7/site-packages')\n",
    "sys.path.append('/global/u1/k/krach/usr/ForSE')\n",
    "from forse.tools.nn_tools import *\n",
    "from forse.tools.img_tools import *\n",
    "from forse.tools.mix_tools import *\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import UpSampling2D, Conv2D, Activation, BatchNormalization\n",
    "from keras.layers import Reshape, Dense, Input\n",
    "from keras.layers import LeakyReLU, Dropout, Flatten, ZeroPadding2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import keras.backend as K\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from  functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    def __init__(self, output_directory, img_size):\n",
    "        self.img_size = img_size\n",
    "        self.channels = 1\n",
    "        self.kernel_size = 5\n",
    "        self.output_directory = output_directory\n",
    "        self.batch_size = 32\n",
    "        \n",
    "    def smooth_accuracy(self, y_true, y_pred):\n",
    "        return K.mean(K.equal(K.round(y_true), K.round(y_pred)))\n",
    "\n",
    "    def build_generator(self):\n",
    "        img_shape = (self.img_size[0], self.img_size[1], self.channels)\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, kernel_size=self.kernel_size, padding=\"same\")) # 64x64x64\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(Conv2D(128, kernel_size=self.kernel_size, padding=\"same\", strides=2)) #32x32x128\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(Conv2D(256, kernel_size=self.kernel_size, padding=\"same\", strides=2)) #16x16x256\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(UpSampling2D())  #32x32x128\n",
    "        model.add(Conv2D(128, kernel_size=self.kernel_size, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(UpSampling2D())  #64x64x64\n",
    "        model.add(Conv2D(64, kernel_size=self.kernel_size, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(Conv2D(self.channels, kernel_size=self.kernel_size, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        img_in = Input(shape=img_shape)\n",
    "        img_out = model(img_in)\n",
    "        return Model(img_in, img_out)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        img_shape = (self.img_size[0], self.img_size[1], self.channels)\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, kernel_size=self.kernel_size, strides=1, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(Conv2D(128, kernel_size=self.kernel_size, strides=2, padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(Conv2D(256, kernel_size=self.kernel_size, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def build_gan(self):\n",
    "        img_shape = (self.img_size[0], self.img_size[1], self.channels)\n",
    "        optimizer = Adam(0.0002, 0.9)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                       optimizer=optimizer,\n",
    "                                       metrics=['accuracy'])\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        z = Input(shape=img_shape)\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                       optimizer=optimizer,\n",
    "                                       metrics=['accuracy'])\n",
    "        valid = self.discriminator(img)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "    def build_gan2(self):\n",
    "        img_shape = (self.img_size[0], self.img_size[1], self.channels)\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                       optimizer=optimizer,\n",
    "                                       metrics=['accuracy'])\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        z = Input(shape=img_shape)\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        valid = self.discriminator(img)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                       optimizer=optimizer,\n",
    "                                       metrics=['accuracy'])\n",
    "        \n",
    "    def build_gan3(self):\n",
    "        img_shape = (self.img_size[0], self.img_size[1], self.channels)\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                       optimizer=optimizer,\n",
    "                                       metrics=['accuracy'])\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        z = Input(shape=img_shape)\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                       optimizer=optimizer,\n",
    "                                       metrics=['accuracy'])\n",
    "        valid = self.discriminator(img)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                       optimizer=optimizer,\n",
    "                                       metrics=['accuracy'])\n",
    "\n",
    "    def train(self, epochs, patches_file, batch_size=32, save_interval=100, swap=None, seed=4324):\n",
    "        self.build_gan3()\n",
    "        print('GENERATOR')\n",
    "        self.generator.summary()\n",
    "        print('COMBINED')\n",
    "        self.combined.summary()\n",
    "        print('DISCRIMINATOR')\n",
    "        self.discriminator.summary()\n",
    "        X_train, X_test, Y_train, Y_test = load_training_set(patches_file, seed=seed)\n",
    "        print(\"Training Data Shape: \", X_train.shape)\n",
    "        half_batch = batch_size // 2\n",
    "        accs = []\n",
    "        for epoch in range(epochs):\n",
    "            print(epoch, datetime.datetime.now().time())\n",
    "            ind_batch = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            g_loss = self.combined.train_on_batch(X_train[ind_batch], np.ones((batch_size, 1)))\n",
    "            target_real = np.ones((half_batch, 1))\n",
    "            target_fake = np.zeros((half_batch, 1))\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = Y_train[idx]\n",
    "            gen_imgs = self.generator.predict(X_train[idx])\n",
    "            if swap:\n",
    "                swap_real = np.random.randint(0, 100, swap)\n",
    "                swap_fake = np.random.randint(0, 100, swap)\n",
    "                for i in range(swap):\n",
    "                    if swap_real[i] < half_batch:\n",
    "                        target_real[swap_real[i]] = 0\n",
    "                    if swap_fake[i] < half_batch:\n",
    "                        target_fake[swap_fake[i]] = 1\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, target_real)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, target_fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            acc = [d_loss_real[1], d_loss_fake[1]]\n",
    "            accs.append(acc)\n",
    "            # Print progress\n",
    "\n",
    "            # If at save interval => save generated image samples, save model files\n",
    "            if epoch % (save_interval) == 0:\n",
    "                print(epoch)\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, target_real)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, target_fake)\n",
    "                gen_imgs_test = self.generator.predict(X_test)\n",
    "                val_fake = self.discriminator.evaluate(gen_imgs_test, np.zeros(len(gen_imgs_test)))\n",
    "                val_real = self.discriminator.evaluate(Y_test, np.ones(len(gen_imgs_test)))\n",
    "                print(val_fake, val_real)\n",
    "                #print(f\"{epoch} [D loss: {d_loss[0]} | D Accuracy: {100 * d_loss[1]}]\")\n",
    "                save_path = self.output_directory + \"/models\"\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                accs_to_save = np.array(accs)\n",
    "                self.discriminator.save(save_path + '/discrim_'+str(epoch)+'.h5')\n",
    "                self.generator.save(save_path + '/generat_'+str(epoch)+'.h5')\n",
    "                np.save(save_path + '/acc_dreal_dfake_'+str(epoch)+'.npy', accs_to_save)\n",
    "        self.discriminator.save(save_path + '/discrim_'+str(epoch)+'.h5')\n",
    "        self.generator.save(save_path + '/generat_'+str(epoch)+'.h5')\n",
    "        np.save(save_path + '/acc_dreal_dfake_'+str(epoch)+'.npy', accs_to_save)\n",
    " \n",
    "    def train3(self, epochs, patches_file, batch_size=32, save_interval=100, swap=None, seed=4324):\n",
    "        X_train, X_test, Y_train, Y_test = load_training_set(patches_file, seed=seed)\n",
    "        print(\"Training Data Shape: \", X_train.shape)\n",
    "        half_batch = batch_size // 2\n",
    "        accs = []\n",
    "        img_shape = (self.img_size[0], self.img_size[1], self.channels)\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        print('DISCRIMINATOR1')\n",
    "        self.discriminator.summary()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                       optimizer=optimizer,\n",
    "                                       metrics=['accuracy'])\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        print('GENERATOR')\n",
    "        self.generator.summary()\n",
    "        z = Input(shape=img_shape)\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                       optimizer=optimizer,\n",
    "                                       metrics=['accuracy'])\n",
    "        valid = self.discriminator(img)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                       optimizer=optimizer,\n",
    "                                       metrics=['accuracy'])\n",
    "        print('COMBINED')\n",
    "        self.combined.summary()\n",
    "        print('DISCRIMINATOR')\n",
    "        self.discriminator.summary()\n",
    "        for epoch in range(epochs):\n",
    "            print(epoch, datetime.datetime.now().time())\n",
    "            ind_batch = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            g_loss = self.combined.train_on_batch(X_train[ind_batch], np.ones((batch_size, 1)))\n",
    "            target_real = np.ones((half_batch, 1))\n",
    "            target_fake = np.zeros((half_batch, 1))\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = Y_train[idx]\n",
    "            gen_imgs = self.generator.predict(X_train[idx])\n",
    "            if swap:\n",
    "                swap_real = np.random.randint(0, 100, swap)\n",
    "                swap_fake = np.random.randint(0, 100, swap)\n",
    "                for i in range(swap):\n",
    "                    if swap_real[i] < half_batch:\n",
    "                        target_real[swap_real[i]] = 0\n",
    "                    if swap_fake[i] < half_batch:\n",
    "                        target_fake[swap_fake[i]] = 1\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, target_real)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, target_fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            acc = [d_loss_real[1], d_loss_fake[1]]\n",
    "            accs.append(acc)\n",
    "            # Print progress\n",
    "\n",
    "            # If at save interval => save generated image samples, save model files\n",
    "            if epoch % (save_interval) == 0:\n",
    "                print(epoch)\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, target_real)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, target_fake)\n",
    "                gen_imgs_test = self.generator.predict(X_test)\n",
    "                val_fake = self.discriminator.evaluate(gen_imgs_test, np.zeros(len(gen_imgs_test)))\n",
    "                val_real = self.discriminator.evaluate(Y_test, np.ones(len(gen_imgs_test)))\n",
    "                print(val_fake, val_real)\n",
    "                #print(f\"{epoch} [D loss: {d_loss[0]} | D Accuracy: {100 * d_loss[1]}]\")\n",
    "                save_path = self.output_directory + \"/models\"\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                accs_to_save = np.array(accs)\n",
    "                self.discriminator.save(save_path + '/discrim_'+str(epoch)+'.h5')\n",
    "                self.generator.save(save_path + '/generat_'+str(epoch)+'.h5')\n",
    "                np.save(save_path + '/acc_dreal_dfake_'+str(epoch)+'.npy', accs_to_save)\n",
    "        self.discriminator.save(save_path + '/discrim_'+str(epoch)+'.h5')\n",
    "        self.generator.save(save_path + '/generat_'+str(epoch)+'.h5')\n",
    "        np.save(save_path + '/acc_dreal_dfake_'+str(epoch)+'.npy', accs_to_save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(output_directory='/global/homes/k/krach/scratch/NNforFG/DCGAN/tests', img_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = '/global/homes/k/krach/scratch/NNforFG/training_set/'\n",
    "training_file = 'training_set_1000patches_20x20deg_T_HR1deg_LR5deg_Npix64_set2.npy'\n",
    "patch_file = training_path+training_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/common/software/tensorflow/gpu-tensorflow/1.15.0-py37/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "WARNING:tensorflow:From /usr/common/software/tensorflow/gpu-tensorflow/1.15.0-py37/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "GENERATOR\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 64, 64, 1)         2054401   \n",
      "=================================================================\n",
      "Total params: 2,054,401\n",
      "Trainable params: 2,053,121\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "COMBINED\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 64, 64, 1)         2054401   \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 1092353   \n",
      "=================================================================\n",
      "Total params: 3,146,754\n",
      "Trainable params: 2,053,121\n",
      "Non-trainable params: 1,093,633\n",
      "_________________________________________________________________\n",
      "DISCRIMINATOR\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 1)                 1092353   \n",
      "=================================================================\n",
      "Total params: 1,092,353\n",
      "Trainable params: 1,091,969\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Training Data Shape:  (800, 64, 64, 1)\n",
      "0 07:13:42.024308\n",
      "WARNING:tensorflow:From /global/homes/k/krach/usr/python_prefix_3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "0\n",
      "200/200 [==============================] - 0s 2ms/step\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "[0.5101239061355591, 0.9800000190734863] [0.5708628749847412, 0.8799999952316284]\n",
      "1 07:13:50.873896\n",
      "1\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "[0.03953349739313126, 1.0] [0.24842485129833222, 0.9700000286102295]\n",
      "2 07:13:55.010182\n",
      "2\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "[0.003590126894414425, 1.0] [0.18067751049995423, 0.9649999737739563]\n",
      "3 07:13:59.573875\n",
      "3\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "[0.015126989632844924, 1.0] [0.0672470960021019, 1.0]\n",
      "4 07:14:03.713871\n",
      "4\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "[4.116205673199147e-05, 1.0] [0.15721440315246582, 0.9399999976158142]\n"
     ]
    }
   ],
   "source": [
    "dcgan.train(epochs=5, patches_file=patch_file, save_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-v1.15.0-gpu",
   "language": "python",
   "name": "tensorflow_gpu_1.15.0_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
